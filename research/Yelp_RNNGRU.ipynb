{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Yelp_RNNGRU.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"TPU"},"cells":[{"cell_type":"code","metadata":{"id":"pifiySPxxOyO","colab_type":"code","outputId":"06478c30-52cc-471f-d02d-bf31d301b30b","executionInfo":{"status":"ok","timestamp":1557179984666,"user_tz":420,"elapsed":21850,"user":{"displayName":"Neha Bindle","photoUrl":"https://lh5.googleusercontent.com/-AKdRkZAe6ns/AAAAAAAAAAI/AAAAAAAAAFk/gdyXnPRgma8/s64/photo.jpg","userId":"09892886772832107016"}},"colab":{"base_uri":"https://localhost:8080/","height":122}},"source":["from google.colab import drive\n","drive.mount('/content/gdrive')\n","!ln -s gdrive/'Team Drives'/'Data Mining Team'/'release' gdata"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/gdrive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"5vnqtyLePiw-","colab_type":"code","colab":{}},"source":["!pip install tf-nightly-gpu-2.0-preview"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"luXf_OC4xj-3","colab_type":"code","colab":{}},"source":["!pip install contractions"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"_gqIeCczxrMV","colab_type":"code","colab":{}},"source":["\n","from tensorflow.python.keras.models import Sequential\n","from tensorflow.python.keras.layers import Dense, GRU, Embedding\n","from tensorflow.python.keras.optimizers import Adam\n","from tensorflow.python.keras.preprocessing.text import Tokenizer\n","from tensorflow.python.keras.preprocessing.sequence import pad_sequences"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"L6B4Xnbrxllw","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"WdZuCaRCx-DJ","colab_type":"text"},"source":["Importing Libraries from Keras.\n"]},{"cell_type":"code","metadata":{"id":"sV3EeIDyxyKV","colab_type":"code","colab":{}},"source":["%matplotlib inline\n","import matplotlib.pyplot as plt\n","import tensorflow as tf\n","import numpy as np\n","from scipy.spatial.distance import cdist"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"loxaQYLfyFod","colab_type":"code","outputId":"f95b2072-8c5b-4244-baad-9a8b445d9e42","executionInfo":{"status":"ok","timestamp":1557179993603,"user_tz":420,"elapsed":204,"user":{"displayName":"Neha Bindle","photoUrl":"https://lh5.googleusercontent.com/-AKdRkZAe6ns/AAAAAAAAAAI/AAAAAAAAAFk/gdyXnPRgma8/s64/photo.jpg","userId":"09892886772832107016"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["#Checking the version on Tensorflow\n","tf.__version__\n"],"execution_count":6,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'1.13.1'"]},"metadata":{"tags":[]},"execution_count":6}]},{"cell_type":"code","metadata":{"id":"aMH6BXckyNPp","colab_type":"code","outputId":"a6172eb3-05f5-4671-916f-e6c661e8d2ed","executionInfo":{"status":"ok","timestamp":1557179994835,"user_tz":420,"elapsed":218,"user":{"displayName":"Neha Bindle","photoUrl":"https://lh5.googleusercontent.com/-AKdRkZAe6ns/AAAAAAAAAAI/AAAAAAAAAFk/gdyXnPRgma8/s64/photo.jpg","userId":"09892886772832107016"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["#Checking the version of Keras\n","tf.keras.__version__\n"],"execution_count":7,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'2.2.4-tf'"]},"metadata":{"tags":[]},"execution_count":7}]},{"cell_type":"code","metadata":{"id":"00m3q3nlB297","colab_type":"code","outputId":"9abf2d1a-a176-4556-e2be-5fc47e06eab1","executionInfo":{"status":"ok","timestamp":1557179996280,"user_tz":420,"elapsed":259,"user":{"displayName":"Neha Bindle","photoUrl":"https://lh5.googleusercontent.com/-AKdRkZAe6ns/AAAAAAAAAAI/AAAAAAAAAFk/gdyXnPRgma8/s64/photo.jpg","userId":"09892886772832107016"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["import pandas\n","pandas.__version__"],"execution_count":8,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'0.24.2'"]},"metadata":{"tags":[]},"execution_count":8}]},{"cell_type":"markdown","metadata":{"id":"lWI92Z8HyZcS","colab_type":"text"},"source":["Load Data\n"]},{"cell_type":"code","metadata":{"id":"Pa9qrdmMyeu9","colab_type":"code","colab":{}},"source":["%matplotlib inline\n","import matplotlib.pyplot as plt\n","import tensorflow as tf\n","import numpy as np\n","from scipy.spatial.distance import cdist"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"O5MA6DYHyRSp","colab_type":"code","colab":{}},"source":["import sqlite3\n","import pandas as pd\n","connection = sqlite3.connect('gdata/yelpHotelData.db')\n","x1 = connection.execute(\"select * FROM review\")"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"T4eFQJ-AyoSS","colab_type":"code","colab":{}},"source":["description = []\n","Class = []\n","\n","data = x1.fetchmany(688329)\n","\n","for x in data:\n","  description.append(x[3])\n","  Class.append(x[8])\n","trainData = {'Class' : Class, 'Description' : description}\n","df_X = pd.DataFrame(trainData)\n","\n","#df_X = df_X.head(20000)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"sXRxY9WYyr0W","colab_type":"code","outputId":"91067d4a-64dd-474f-e613-69233f7803d5","executionInfo":{"status":"ok","timestamp":1557180014219,"user_tz":420,"elapsed":12722,"user":{"displayName":"Neha Bindle","photoUrl":"https://lh5.googleusercontent.com/-AKdRkZAe6ns/AAAAAAAAAAI/AAAAAAAAAFk/gdyXnPRgma8/s64/photo.jpg","userId":"09892886772832107016"}},"colab":{"base_uri":"https://localhost:8080/","height":68}},"source":["#Convert NR->N , YR->Y\n","df_X.loc[df_X['Class'] == \"NR\", 'Class'] = \"N\"\n","df_X.loc[df_X['Class'] == \"YR\", 'Class'] = \"Y\"\n","df_X['Class'].value_counts()"],"execution_count":12,"outputs":[{"output_type":"execute_result","data":{"text/plain":["N    420785\n","Y    267544\n","Name: Class, dtype: int64"]},"metadata":{"tags":[]},"execution_count":12}]},{"cell_type":"code","metadata":{"id":"5hy4GDkkG0In","colab_type":"code","colab":{}},"source":["df_X['Class'] = df_X['Class'].apply(lambda x:1 if x=='Y' else 0)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"KW3juvhhHma3","colab_type":"code","outputId":"74693609-ba5f-466c-8ae4-d5d07296f65b","executionInfo":{"status":"ok","timestamp":1557180014222,"user_tz":420,"elapsed":10182,"user":{"displayName":"Neha Bindle","photoUrl":"https://lh5.googleusercontent.com/-AKdRkZAe6ns/AAAAAAAAAAI/AAAAAAAAAFk/gdyXnPRgma8/s64/photo.jpg","userId":"09892886772832107016"}},"colab":{"base_uri":"https://localhost:8080/","height":1071}},"source":["df_X['Class']"],"execution_count":14,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0         0\n","1         0\n","2         0\n","3         0\n","4         0\n","5         0\n","6         0\n","7         0\n","8         0\n","9         0\n","10        0\n","11        0\n","12        0\n","13        0\n","14        0\n","15        0\n","16        0\n","17        0\n","18        0\n","19        0\n","20        0\n","21        0\n","22        0\n","23        0\n","24        0\n","25        0\n","26        0\n","27        0\n","28        0\n","29        0\n","         ..\n","688299    1\n","688300    1\n","688301    1\n","688302    1\n","688303    1\n","688304    1\n","688305    1\n","688306    1\n","688307    1\n","688308    1\n","688309    1\n","688310    1\n","688311    0\n","688312    1\n","688313    1\n","688314    1\n","688315    1\n","688316    1\n","688317    0\n","688318    1\n","688319    1\n","688320    1\n","688321    1\n","688322    1\n","688323    1\n","688324    1\n","688325    1\n","688326    1\n","688327    1\n","688328    1\n","Name: Class, Length: 688329, dtype: int64"]},"metadata":{"tags":[]},"execution_count":14}]},{"cell_type":"code","metadata":{"id":"0uEk2bXUH-hS","colab_type":"code","colab":{}},"source":["texts = df_X['Description'].values\n","labels = df_X['Class'].values"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"6ypoKOtmIYWy","colab_type":"code","colab":{}},"source":["MAX_NUM_WORDS=1000\n","MAX_SEQUENCE_LENGTH=100"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Um0fxPnzIhUU","colab_type":"code","colab":{}},"source":["\n","tokenizer = Tokenizer(num_words=MAX_NUM_WORDS)\n","tokenizer.fit_on_texts(texts)\n","sequences = tokenizer.texts_to_sequences(texts)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"0wxZw1G_yvwx","colab_type":"code","colab":{}},"source":["from sklearn.model_selection import train_test_split\n","import pickle"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"azw9ygo4zI5t","colab_type":"code","colab":{}},"source":["X_train, X_test, y_train, y_test = train_test_split(df_X['Description'],df_X['Class'], test_size=0.3, random_state=42)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"WEeoIK6zzQqQ","colab_type":"code","outputId":"2baf2a37-e366-47c4-c9c4-cf4224a58fca","executionInfo":{"status":"ok","timestamp":1557180241629,"user_tz":420,"elapsed":231436,"user":{"displayName":"Neha Bindle","photoUrl":"https://lh5.googleusercontent.com/-AKdRkZAe6ns/AAAAAAAAAAI/AAAAAAAAAFk/gdyXnPRgma8/s64/photo.jpg","userId":"09892886772832107016"}},"colab":{"base_uri":"https://localhost:8080/","height":51}},"source":["#Checking the shape of Train and Test Data\n","print(X_train.shape, X_test.shape)\n","print(y_train.shape, y_test.shape)"],"execution_count":20,"outputs":[{"output_type":"stream","text":["(481830,) (206499,)\n","(481830,) (206499,)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"KHoTHysvznFd","colab_type":"code","outputId":"41722d31-3da3-4257-91dd-e99b96874eb6","executionInfo":{"status":"ok","timestamp":1557180241630,"user_tz":420,"elapsed":230205,"user":{"displayName":"Neha Bindle","photoUrl":"https://lh5.googleusercontent.com/-AKdRkZAe6ns/AAAAAAAAAAI/AAAAAAAAAFk/gdyXnPRgma8/s64/photo.jpg","userId":"09892886772832107016"}},"colab":{"base_uri":"https://localhost:8080/","height":51}},"source":["#Checking the length of train and test data\n","print(\"Train-set size: \", len(X_train))\n","print(\"Test-set size:  \", len(X_test))"],"execution_count":21,"outputs":[{"output_type":"stream","text":["Train-set size:  481830\n","Test-set size:   206499\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"8mk2YOpd0bnT","colab_type":"code","colab":{}},"source":["#Combine into one data-set for some uses below.\n","data_text = X_train + X_test"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"B9HMVqX805Vo","colab_type":"code","outputId":"04c9f0f0-e8ab-4b91-de7a-6bfd9d386935","executionInfo":{"status":"ok","timestamp":1557180242292,"user_tz":420,"elapsed":229629,"user":{"displayName":"Neha Bindle","photoUrl":"https://lh5.googleusercontent.com/-AKdRkZAe6ns/AAAAAAAAAAI/AAAAAAAAAFk/gdyXnPRgma8/s64/photo.jpg","userId":"09892886772832107016"}},"colab":{"base_uri":"https://localhost:8080/","height":54}},"source":["#Printing an example to see how data looks like\n","X_train[1]"],"execution_count":23,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'The only place inside the Loop that you can stay for $55/night. Also, the only place you can have a picnic dinner and get a little frisky on the 17th floor roof and then wake up in your room the next morning to an army of ants going in on your picnic leftovers.'"]},"metadata":{"tags":[]},"execution_count":23}]},{"cell_type":"code","metadata":{"id":"cyJZjUU-1GZT","colab_type":"code","outputId":"bbc38a40-1ee5-497b-b450-e4b0ab5612ef","executionInfo":{"status":"ok","timestamp":1557180242293,"user_tz":420,"elapsed":228708,"user":{"displayName":"Neha Bindle","photoUrl":"https://lh5.googleusercontent.com/-AKdRkZAe6ns/AAAAAAAAAAI/AAAAAAAAAFk/gdyXnPRgma8/s64/photo.jpg","userId":"09892886772832107016"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["y_train[1]"],"execution_count":24,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0"]},"metadata":{"tags":[]},"execution_count":24}]},{"cell_type":"markdown","metadata":{"id":"GxZAyxGu1Nkq","colab_type":"text"},"source":["Tokenizer\n","A neural network cannot work directly on text-strings so we must convert it somehow. There are two steps in this conversion, the first step is called the \"tokenizer\" which converts words to integers and is done on the data-set before it is input to the neural network. The second step is an integrated part of the neural network itself and is called the \"embedding\"-layer, which is described further below.\n","\n","We may instruct the tokenizer to only use e.g. the 10000 most popular words from the data-set.\n"]},{"cell_type":"code","metadata":{"id":"sLMKCouK1VcM","colab_type":"code","colab":{}},"source":["num_words = 10000\n","tokenizer = Tokenizer(num_words=num_words)\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"gQU_A1N01b96","colab_type":"text"},"source":["The tokenizer can then be \"fitted\" to the data-set. This scans through all the text and strips it from unwanted characters such as punctuation, and also converts it to lower-case characters. The tokenizer then builds a vocabulary of all unique words along with various data-structures for accessing the data.\n","\n"]},{"cell_type":"code","metadata":{"id":"eYGSiSEb1ebL","colab_type":"code","outputId":"55eaa6f1-1314-425e-ce71-32f7f23e59f7","executionInfo":{"status":"ok","timestamp":1557180330818,"user_tz":420,"elapsed":314583,"user":{"displayName":"Neha Bindle","photoUrl":"https://lh5.googleusercontent.com/-AKdRkZAe6ns/AAAAAAAAAAI/AAAAAAAAAFk/gdyXnPRgma8/s64/photo.jpg","userId":"09892886772832107016"}},"colab":{"base_uri":"https://localhost:8080/","height":51}},"source":["#Tokenization of train data\n","%%time\n","X_train_token = tokenizer.fit_on_texts(X_train)"],"execution_count":26,"outputs":[{"output_type":"stream","text":["CPU times: user 1min 27s, sys: 130 ms, total: 1min 27s\n","Wall time: 1min 27s\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"t8DpcpXpge2d","colab_type":"code","colab":{}},"source":["# df_X=X_train_token\n","# df_X.head()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"sNE28RkshCQb","colab_type":"text"},"source":[""]},{"cell_type":"code","metadata":{"id":"Wm7lg8euzMAL","colab_type":"code","colab":{}},"source":["# pickle_out = open(\"gdata/train_token.pickle\",\"wb\")\n","# pickle.dump(X_train_token, pickle_out)\n","# pickle_out.close()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"HlNIXf2a1z0D","colab_type":"code","outputId":"f6adfb38-99d2-49f9-bf72-20da9747ea37","executionInfo":{"status":"ok","timestamp":1557180368955,"user_tz":420,"elapsed":349773,"user":{"displayName":"Neha Bindle","photoUrl":"https://lh5.googleusercontent.com/-AKdRkZAe6ns/AAAAAAAAAAI/AAAAAAAAAFk/gdyXnPRgma8/s64/photo.jpg","userId":"09892886772832107016"}},"colab":{"base_uri":"https://localhost:8080/","height":51}},"source":["#Tokenization of test data\n","%%time\n","X_test_token = tokenizer.fit_on_texts(X_test)\n","# pickle_out_test = open(\"test_token.pickle\",\"wb\")\n","# pickle.dump(X_test_token, pickle_out_test)\n","# pickle_out_test.close()"],"execution_count":29,"outputs":[{"output_type":"stream","text":["CPU times: user 38 s, sys: 80.1 ms, total: 38.1 s\n","Wall time: 38.1 s\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"lrkQiKCt185i","colab_type":"code","colab":{}},"source":["#set num_words=None above, and then it will automatically be set to the vocabulary-size here.\n","\n","\n","if num_words is None:\n","    num_words = len(tokenizer.word_index)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"z5cR1ZEK2JhX","colab_type":"text"},"source":["We can then inspect the vocabulary that has been gathered by the tokenizer. This is ordered by the number of occurrences of the words in the data-set. These integer-numbers are called word indices or \"tokens\" because they uniquely identify each word in the vocabulary."]},{"cell_type":"code","metadata":{"id":"h89DHq5K2GsI","colab_type":"code","outputId":"b686462b-d3d4-4214-9370-afe3a4021eeb","executionInfo":{"status":"ok","timestamp":1557180368959,"user_tz":420,"elapsed":346178,"user":{"displayName":"Neha Bindle","photoUrl":"https://lh5.googleusercontent.com/-AKdRkZAe6ns/AAAAAAAAAAI/AAAAAAAAAFk/gdyXnPRgma8/s64/photo.jpg","userId":"09892886772832107016"}},"colab":{"base_uri":"https://localhost:8080/","height":17034}},"source":["tokenizer.word_index\n"],"execution_count":31,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'the': 1,\n"," 'and': 2,\n"," 'a': 3,\n"," 'i': 4,\n"," 'to': 5,\n"," 'of': 6,\n"," 'was': 7,\n"," 'in': 8,\n"," 'is': 9,\n"," 'it': 10,\n"," 'for': 11,\n"," 'that': 12,\n"," 'but': 13,\n"," 'with': 14,\n"," 'you': 15,\n"," 'my': 16,\n"," 'on': 17,\n"," 'this': 18,\n"," 'they': 19,\n"," 'have': 20,\n"," 'we': 21,\n"," 'not': 22,\n"," 'at': 23,\n"," 'so': 24,\n"," 'had': 25,\n"," 'are': 26,\n"," 'were': 27,\n"," 'good': 28,\n"," 'place': 29,\n"," 'as': 30,\n"," 'be': 31,\n"," 'like': 32,\n"," 'here': 33,\n"," 'me': 34,\n"," 'there': 35,\n"," 'out': 36,\n"," 'all': 37,\n"," 'food': 38,\n"," 'if': 39,\n"," 'just': 40,\n"," 'one': 41,\n"," '\\xa0': 42,\n"," \"it's\": 43,\n"," 'or': 44,\n"," 'get': 45,\n"," 'up': 46,\n"," 'from': 47,\n"," 'great': 48,\n"," 'very': 49,\n"," 'some': 50,\n"," '\\xa0i': 51,\n"," 'really': 52,\n"," 'their': 53,\n"," 'when': 54,\n"," '\\xa0the': 55,\n"," 'about': 56,\n"," 'an': 57,\n"," 'time': 58,\n"," 'which': 59,\n"," 'can': 60,\n"," 'go': 61,\n"," 'our': 62,\n"," 'your': 63,\n"," 'more': 64,\n"," 'what': 65,\n"," 'would': 66,\n"," 'back': 67,\n"," 'also': 68,\n"," 'service': 69,\n"," 'by': 70,\n"," 'only': 71,\n"," 'too': 72,\n"," \"don't\": 73,\n"," 'no': 74,\n"," 'been': 75,\n"," 'nice': 76,\n"," \"i'm\": 77,\n"," 'little': 78,\n"," 'other': 79,\n"," 'because': 80,\n"," 'got': 81,\n"," 'well': 82,\n"," 'pretty': 83,\n"," 'do': 84,\n"," 'than': 85,\n"," 'even': 86,\n"," 'will': 87,\n"," 'has': 88,\n"," 'much': 89,\n"," 'them': 90,\n"," 'people': 91,\n"," 'us': 92,\n"," 'after': 93,\n"," \"i've\": 94,\n"," \"didn't\": 95,\n"," 'bar': 96,\n"," 'love': 97,\n"," 'think': 98,\n"," 'know': 99,\n"," 'he': 100,\n"," 'night': 101,\n"," 'best': 102,\n"," 'could': 103,\n"," 'over': 104,\n"," 'way': 105,\n"," 'did': 106,\n"," 'first': 107,\n"," 'restaurant': 108,\n"," 'came': 109,\n"," 'always': 110,\n"," 'who': 111,\n"," 'menu': 112,\n"," '2': 113,\n"," 'she': 114,\n"," 'off': 115,\n"," 'make': 116,\n"," 'two': 117,\n"," 'day': 118,\n"," 'better': 119,\n"," 'come': 120,\n"," 'chicken': 121,\n"," 'right': 122,\n"," 'how': 123,\n"," 'went': 124,\n"," 'ordered': 125,\n"," 'around': 126,\n"," 'try': 127,\n"," 'order': 128,\n"," 'then': 129,\n"," 'going': 130,\n"," 'down': 131,\n"," 'see': 132,\n"," 'room': 133,\n"," 'few': 134,\n"," 'want': 135,\n"," '5': 136,\n"," 'made': 137,\n"," 'bit': 138,\n"," 'still': 139,\n"," 'though': 140,\n"," 'friendly': 141,\n"," '3': 142,\n"," 'area': 143,\n"," 'definitely': 144,\n"," 'never': 145,\n"," 'while': 146,\n"," 'into': 147,\n"," 'before': 148,\n"," 'any': 149,\n"," 'am': 150,\n"," 'cheese': 151,\n"," 'say': 152,\n"," 'small': 153,\n"," 'since': 154,\n"," 'sure': 155,\n"," 'lot': 156,\n"," 'staff': 157,\n"," 'find': 158,\n"," 'new': 159,\n"," 'take': 160,\n"," 'most': 161,\n"," 'something': 162,\n"," 'again': 163,\n"," 'where': 164,\n"," 'delicious': 165,\n"," 'now': 166,\n"," \"you're\": 167,\n"," 'lunch': 168,\n"," 'next': 169,\n"," 'sauce': 170,\n"," '\\xa0it': 171,\n"," 'her': 172,\n"," \"wasn't\": 173,\n"," 'table': 174,\n"," 'many': 175,\n"," 'dinner': 176,\n"," 'eat': 177,\n"," 'big': 178,\n"," 'wait': 179,\n"," 'fresh': 180,\n"," 'thing': 181,\n"," 'bad': 182,\n"," 'experience': 183,\n"," 'salad': 184,\n"," 'being': 185,\n"," 'store': 186,\n"," 'ever': 187,\n"," \"can't\": 188,\n"," '4': 189,\n"," '1': 190,\n"," 'everything': 191,\n"," 'last': 192,\n"," 'said': 193,\n"," 'pizza': 194,\n"," 'location': 195,\n"," 'long': 196,\n"," 'side': 197,\n"," 'give': 198,\n"," 'drinks': 199,\n"," 'wine': 200,\n"," 'hot': 201,\n"," '\\xa0they': 202,\n"," 'enough': 203,\n"," 'things': 204,\n"," 'its': 205,\n"," 'need': 206,\n"," 'every': 207,\n"," 'another': 208,\n"," 'stars': 209,\n"," 'meal': 210,\n"," '\\xa0we': 211,\n"," 'free': 212,\n"," 'times': 213,\n"," \"that's\": 214,\n"," 'work': 215,\n"," 'looking': 216,\n"," 'actually': 217,\n"," 'feel': 218,\n"," 'beer': 219,\n"," 'price': 220,\n"," 'those': 221,\n"," 'minutes': 222,\n"," \"i'd\": 223,\n"," 'selection': 224,\n"," 'quite': 225,\n"," 'probably': 226,\n"," 'home': 227,\n"," 'sweet': 228,\n"," 'hotel': 229,\n"," 'amazing': 230,\n"," 'friend': 231,\n"," 'prices': 232,\n"," 'drink': 233,\n"," 'old': 234,\n"," 'his': 235,\n"," 'tasty': 236,\n"," 'took': 237,\n"," 'both': 238,\n"," 'worth': 239,\n"," 'parking': 240,\n"," '10': 241,\n"," 'happy': 242,\n"," 'friends': 243,\n"," 'these': 244,\n"," 'kind': 245,\n"," 'check': 246,\n"," 'should': 247,\n"," 'thought': 248,\n"," 'coffee': 249,\n"," 'fun': 250,\n"," 'huge': 251,\n"," 'awesome': 252,\n"," 'super': 253,\n"," 'wanted': 254,\n"," 'away': 255,\n"," 'places': 256,\n"," 'look': 257,\n"," 'favorite': 258,\n"," 'nothing': 259,\n"," 'different': 260,\n"," 'full': 261,\n"," 'ok': 262,\n"," 'same': 263,\n"," 'found': 264,\n"," 'cool': 265,\n"," 'tried': 266,\n"," 'meat': 267,\n"," 'sandwich': 268,\n"," 'large': 269,\n"," 'special': 270,\n"," 'why': 271,\n"," 'perfect': 272,\n"," 'bread': 273,\n"," 'decent': 274,\n"," 'top': 275,\n"," 'taste': 276,\n"," 'through': 277,\n"," 'cream': 278,\n"," 'fries': 279,\n"," 'once': 280,\n"," 'burger': 281,\n"," 'hour': 282,\n"," 'dish': 283,\n"," 'years': 284,\n"," 'line': 285,\n"," 'maybe': 286,\n"," 'fried': 287,\n"," 'spot': 288,\n"," \"i'll\": 289,\n"," 'open': 290,\n"," 'inside': 291,\n"," 'anything': 292,\n"," 'outside': 293,\n"," \"there's\": 294,\n"," 'breakfast': 295,\n"," 'chocolate': 296,\n"," 'street': 297,\n"," 'each': 298,\n"," 'getting': 299,\n"," 'clean': 300,\n"," 'used': 301,\n"," 'review': 302,\n"," 'visit': 303,\n"," 'soup': 304,\n"," 'rice': 305,\n"," 'sushi': 306,\n"," 'high': 307,\n"," 'star': 308,\n"," 'asked': 309,\n"," 'beef': 310,\n"," 'yelp': 311,\n"," 'couple': 312,\n"," 'half': 313,\n"," 'however': 314,\n"," 'walk': 315,\n"," 'quality': 316,\n"," 'end': 317,\n"," 'flavor': 318,\n"," 'stuff': 319,\n"," '\\xa0and': 320,\n"," 'excellent': 321,\n"," 'else': 322,\n"," 'least': 323,\n"," 'during': 324,\n"," 'oh': 325,\n"," 'having': 326,\n"," 'house': 327,\n"," 'without': 328,\n"," 'told': 329,\n"," 'served': 330,\n"," 'left': 331,\n"," 'looked': 332,\n"," 'front': 333,\n"," 'city': 334,\n"," 'usually': 335,\n"," 'hard': 336,\n"," 'course': 337,\n"," 'fish': 338,\n"," 'ice': 339,\n"," 'almost': 340,\n"," 'whole': 341,\n"," 'tables': 342,\n"," 'put': 343,\n"," 'stop': 344,\n"," 'part': 345,\n"," 'everyone': 346,\n"," 'items': 347,\n"," 'three': 348,\n"," 'pork': 349,\n"," \"\\xa0it's\": 350,\n"," 'may': 351,\n"," 'cheap': 352,\n"," 'yes': 353,\n"," 'overall': 354,\n"," 'recommend': 355,\n"," 'water': 356,\n"," 'dishes': 357,\n"," 'chicago': 358,\n"," 'decided': 359,\n"," 'music': 360,\n"," 'dessert': 361,\n"," \"isn't\": 362,\n"," '\\xa0but': 363,\n"," 'atmosphere': 364,\n"," 'such': 365,\n"," 'especially': 366,\n"," 'red': 367,\n"," 'spicy': 368,\n"," 'might': 369,\n"," 'loved': 370,\n"," 'less': 371,\n"," 'makes': 372,\n"," 'shop': 373,\n"," '6': 374,\n"," 'far': 375,\n"," '\\xa0my': 376,\n"," 'own': 377,\n"," 'park': 378,\n"," 'dining': 379,\n"," '\\xa0this': 380,\n"," 'done': 381,\n"," 'enjoy': 382,\n"," 'use': 383,\n"," 'hours': 384,\n"," 'town': 385,\n"," 'enjoyed': 386,\n"," 'liked': 387,\n"," 'must': 388,\n"," 'eating': 389,\n"," 'seemed': 390,\n"," 'him': 391,\n"," 'close': 392,\n"," 'door': 393,\n"," \"doesn't\": 394,\n"," 'quick': 395,\n"," 'car': 396,\n"," 'party': 397,\n"," 'does': 398,\n"," 'server': 399,\n"," 'space': 400,\n"," 'show': 401,\n"," 'lots': 402,\n"," 'week': 403,\n"," 'coming': 404,\n"," 'fan': 405,\n"," 'ask': 406,\n"," 'steak': 407,\n"," 'let': 408,\n"," 'able': 409,\n"," '20': 410,\n"," 'etc': 411,\n"," 'although': 412,\n"," 'restaurants': 413,\n"," '30': 414,\n"," 'someone': 415,\n"," 'trying': 416,\n"," 'tea': 417,\n"," 'pay': 418,\n"," 'either': 419,\n"," 'stay': 420,\n"," 'decor': 421,\n"," 'guy': 422,\n"," 'myself': 423,\n"," 'year': 424,\n"," 'felt': 425,\n"," 'sit': 426,\n"," 'group': 427,\n"," 'fact': 428,\n"," 'shrimp': 429,\n"," 'fast': 430,\n"," 'until': 431,\n"," \"couldn't\": 432,\n"," 'style': 433,\n"," 'person': 434,\n"," 'name': 435,\n"," 'business': 436,\n"," 'deal': 437,\n"," 'yet': 438,\n"," 'tell': 439,\n"," 'okay': 440,\n"," 'fine': 441,\n"," 'plate': 442,\n"," 'gave': 443,\n"," 'tasted': 444,\n"," 'guess': 445,\n"," 'live': 446,\n"," 'days': 447,\n"," 'seems': 448,\n"," 'started': 449,\n"," 'cake': 450,\n"," 'buy': 451,\n"," 'bring': 452,\n"," 'local': 453,\n"," 'waiting': 454,\n"," 'walked': 455,\n"," 'plus': 456,\n"," 'white': 457,\n"," 'call': 458,\n"," 'saw': 459,\n"," 'comes': 460,\n"," 'instead': 461,\n"," 'called': 462,\n"," \"they're\": 463,\n"," 'needed': 464,\n"," 'late': 465,\n"," 'finally': 466,\n"," 'real': 467,\n"," 'beautiful': 468,\n"," 'busy': 469,\n"," '7': 470,\n"," 'options': 471,\n"," '8': 472,\n"," 'fantastic': 473,\n"," 'keep': 474,\n"," 'reviews': 475,\n"," 'family': 476,\n"," 'later': 477,\n"," 'easy': 478,\n"," 'cute': 479,\n"," 'expensive': 480,\n"," '\\xa0if': 481,\n"," 'extra': 482,\n"," 'seating': 483,\n"," 'size': 484,\n"," 'point': 485,\n"," 'cold': 486,\n"," '15': 487,\n"," 'cooked': 488,\n"," 'green': 489,\n"," 'list': 490,\n"," 'several': 491,\n"," 'wonderful': 492,\n"," '50': 493,\n"," 'floor': 494,\n"," 'roll': 495,\n"," 'second': 496,\n"," 'helpful': 497,\n"," 'remember': 498,\n"," \"wouldn't\": 499,\n"," \"you'll\": 500,\n"," 'trip': 501,\n"," 'expect': 502,\n"," '\\xa0there': 503,\n"," 'waitress': 504,\n"," 'warm': 505,\n"," 'light': 506,\n"," 'wrong': 507,\n"," 'pick': 508,\n"," 'help': 509,\n"," 'glass': 510,\n"," 'early': 511,\n"," 'reason': 512,\n"," 'between': 513,\n"," 'rooms': 514,\n"," '\\xa0you': 515,\n"," 'care': 516,\n"," 'money': 517,\n"," 'bacon': 518,\n"," 'crowd': 519,\n"," 'w': 520,\n"," 'run': 521,\n"," 'across': 522,\n"," 'weekend': 523,\n"," 'job': 524,\n"," 'thai': 525,\n"," 'start': 526,\n"," 'brought': 527,\n"," 'regular': 528,\n"," \"won't\": 529,\n"," 'rolls': 530,\n"," 'plenty': 531,\n"," 'mind': 532,\n"," 'ended': 533,\n"," 'crowded': 534,\n"," 'french': 535,\n"," 'seem': 536,\n"," 'set': 537,\n"," 'gets': 538,\n"," 'wish': 539,\n"," 'mean': 540,\n"," 'looks': 541,\n"," 'rather': 542,\n"," 'chips': 543,\n"," 'ago': 544,\n"," 'saturday': 545,\n"," 'totally': 546,\n"," 'owner': 547,\n"," 'sandwiches': 548,\n"," 'yummy': 549,\n"," 'hit': 550,\n"," 'offer': 551,\n"," 'seen': 552,\n"," 'life': 553,\n"," 'walking': 554,\n"," '\\xa0so': 555,\n"," 'packed': 556,\n"," 'interesting': 557,\n"," 'view': 558,\n"," 'past': 559,\n"," 'drive': 560,\n"," 'morning': 561,\n"," 'counter': 562,\n"," 'making': 563,\n"," 'sat': 564,\n"," 'already': 565,\n"," 'choice': 566,\n"," 'average': 567,\n"," 'along': 568,\n"," 'near': 569,\n"," 'often': 570,\n"," 'evening': 571,\n"," 'itself': 572,\n"," 'kids': 573,\n"," 'cut': 574,\n"," 'main': 575,\n"," 'serve': 576,\n"," 'perfectly': 577,\n"," 'waiter': 578,\n"," 'flavors': 579,\n"," 'customer': 580,\n"," 'leave': 581,\n"," 'absolutely': 582,\n"," 'four': 583,\n"," 'world': 584,\n"," 'dog': 585,\n"," 'italian': 586,\n"," 'located': 587,\n"," 'guys': 588,\n"," 'seated': 589,\n"," 'variety': 590,\n"," 'brunch': 591,\n"," 'event': 592,\n"," 'ate': 593,\n"," 'under': 594,\n"," 'chinese': 595,\n"," 'bbq': 596,\n"," 'neighborhood': 597,\n"," 'today': 598,\n"," 'working': 599,\n"," 'type': 600,\n"," 'hair': 601,\n"," 'crab': 602,\n"," 'sometimes': 603,\n"," 'grilled': 604,\n"," 'knew': 605,\n"," 'short': 606,\n"," '\\xa0a': 607,\n"," 'sitting': 608,\n"," 'arrived': 609,\n"," 'head': 610,\n"," 'la': 611,\n"," 'quickly': 612,\n"," 'impressed': 613,\n"," 'black': 614,\n"," 'amount': 615,\n"," 'disappointed': 616,\n"," 'patio': 617,\n"," 'downtown': 618,\n"," 'cafe': 619,\n"," 'kitchen': 620,\n"," 'reasonable': 621,\n"," 'man': 622,\n"," 'seriously': 623,\n"," 'garlic': 624,\n"," 'http': 625,\n"," 'shopping': 626,\n"," 'egg': 627,\n"," 'mexican': 628,\n"," 'dry': 629,\n"," 'extremely': 630,\n"," 'available': 631,\n"," 'believe': 632,\n"," 'doing': 633,\n"," 'sunday': 634,\n"," 'potato': 635,\n"," 'heard': 636,\n"," 'game': 637,\n"," 'return': 638,\n"," 'watch': 639,\n"," 'entire': 640,\n"," 'comfortable': 641,\n"," 'given': 642,\n"," 'problem': 643,\n"," 'portions': 644,\n"," 'potatoes': 645,\n"," 'pasta': 646,\n"," 'behind': 647,\n"," 'club': 648,\n"," 'attentive': 649,\n"," 'girl': 650,\n"," 'stopped': 651,\n"," 'slow': 652,\n"," 'tacos': 653,\n"," '9': 654,\n"," 'soon': 655,\n"," 'building': 656,\n"," 'bite': 657,\n"," 'butter': 658,\n"," 'hand': 659,\n"," 'anyone': 660,\n"," 'bottle': 661,\n"," 'burgers': 662,\n"," 'center': 663,\n"," 'priced': 664,\n"," 'beers': 665,\n"," 'pieces': 666,\n"," 'b': 667,\n"," 'seafood': 668,\n"," 'rest': 669,\n"," 'friday': 670,\n"," 'appetizer': 671,\n"," 'ones': 672,\n"," 'eggs': 673,\n"," 'surprised': 674,\n"," \"\\xa0i'm\": 675,\n"," 'sort': 676,\n"," '12': 677,\n"," 'idea': 678,\n"," 'others': 679,\n"," 'ready': 680,\n"," 'beans': 681,\n"," '\\xa0not': 682,\n"," 'dark': 683,\n"," 'read': 684,\n"," 'highly': 685,\n"," \"haven't\": 686,\n"," 'bathroom': 687,\n"," 'five': 688,\n"," 'taking': 689,\n"," 'pricey': 690,\n"," 'kept': 691,\n"," 'date': 692,\n"," 'market': 693,\n"," 'crispy': 694,\n"," 'including': 695,\n"," 'anyway': 696,\n"," 'yourself': 697,\n"," 'tasting': 698,\n"," 'school': 699,\n"," \"weren't\": 700,\n"," 'middle': 701,\n"," 'tip': 702,\n"," 'bowl': 703,\n"," 'simple': 704,\n"," 'add': 705,\n"," 'wall': 706,\n"," 'sign': 707,\n"," \"aren't\": 708,\n"," 'portion': 709,\n"," 'filled': 710,\n"," 'card': 711,\n"," 'husband': 712,\n"," 'summer': 713,\n"," 'noodles': 714,\n"," 'together': 715,\n"," 'tiny': 716,\n"," 'mall': 717,\n"," 'san': 718,\n"," 'feeling': 719,\n"," 'ambiance': 720,\n"," 'case': 721,\n"," 'recently': 722,\n"," 'birthday': 723,\n"," 'tomato': 724,\n"," 'note': 725,\n"," 'soft': 726,\n"," 'standard': 727,\n"," 'completely': 728,\n"," 'salsa': 729,\n"," 'salmon': 730,\n"," 'solid': 731,\n"," 'bartender': 732,\n"," 'pool': 733,\n"," 'thanks': 734,\n"," 'glad': 735,\n"," 'ordering': 736,\n"," 'loud': 737,\n"," 'bought': 738,\n"," 'office': 739,\n"," 'spend': 740,\n"," 'number': 741,\n"," 'yeah': 742,\n"," 'miss': 743,\n"," 'unique': 744,\n"," 'tuna': 745,\n"," 'lovely': 746,\n"," 'non': 747,\n"," 'prepared': 748,\n"," 'gone': 749,\n"," 'change': 750,\n"," 'afternoon': 751,\n"," 'exactly': 752,\n"," 'sausage': 753,\n"," 'www': 754,\n"," 'please': 755,\n"," 'choose': 756,\n"," 'within': 757,\n"," 'crust': 758,\n"," 'com': 759,\n"," 'cup': 760,\n"," 'bill': 761,\n"," 'empty': 762,\n"," 'corner': 763,\n"," 'appetizers': 764,\n"," 'low': 765,\n"," 'cost': 766,\n"," 'blue': 767,\n"," 'expected': 768,\n"," 'option': 769,\n"," 'phone': 770,\n"," '25': 771,\n"," 'art': 772,\n"," 'crazy': 773,\n"," 'yum': 774,\n"," 'buffet': 775,\n"," 'hungry': 776,\n"," 'waited': 777,\n"," 'fruit': 778,\n"," 'wedding': 779,\n"," 'stores': 780,\n"," 'stayed': 781,\n"," 'tender': 782,\n"," 'specials': 783,\n"," 'book': 784,\n"," 'beach': 785,\n"," 'outdoor': 786,\n"," '\\xa0he': 787,\n"," 'slightly': 788,\n"," 'lobster': 789,\n"," 'grab': 790,\n"," 'typical': 791,\n"," 'whatever': 792,\n"," 'hear': 793,\n"," 'needs': 794,\n"," 'onion': 795,\n"," 'seat': 796,\n"," 'wow': 797,\n"," 'flavorful': 798,\n"," 'hate': 799,\n"," 'piece': 800,\n"," 'bed': 801,\n"," 'minute': 802,\n"," 'twice': 803,\n"," 'airport': 804,\n"," 'joint': 805,\n"," 'ingredients': 806,\n"," 'entrees': 807,\n"," 'fairly': 808,\n"," 'plates': 809,\n"," 'folks': 810,\n"," 'entree': 811,\n"," 'months': 812,\n"," 'weird': 813,\n"," 'thank': 814,\n"," 'mix': 815,\n"," 'damn': 816,\n"," 'cash': 817,\n"," 'based': 818,\n"," 'stand': 819,\n"," 'charge': 820,\n"," 'oil': 821,\n"," 'play': 822,\n"," 'offered': 823,\n"," 'closed': 824,\n"," 'watching': 825,\n"," 'certainly': 826,\n"," 'onions': 827,\n"," 'goes': 828,\n"," 'opened': 829,\n"," 'c': 830,\n"," 'bland': 831,\n"," '\\xa0she': 832,\n"," 'taco': 833,\n"," 'pie': 834,\n"," 'lamb': 835,\n"," 'lady': 836,\n"," 'mouth': 837,\n"," 'asian': 838,\n"," 'chef': 839,\n"," 'chain': 840,\n"," 'section': 841,\n"," 'mixed': 842,\n"," 'kinda': 843,\n"," 'pleasant': 844,\n"," 'per': 845,\n"," 'choices': 846,\n"," 'customers': 847,\n"," 'thin': 848,\n"," 'company': 849,\n"," '\\xa0for': 850,\n"," 'recommended': 851,\n"," 'seats': 852,\n"," 'tour': 853,\n"," 'upon': 854,\n"," 'paid': 855,\n"," 'above': 856,\n"," 'corn': 857,\n"," 'due': 858,\n"," 'class': 859,\n"," 'bars': 860,\n"," 'talk': 861,\n"," 'deep': 862,\n"," 'basically': 863,\n"," 'lounge': 864,\n"," 'giving': 865,\n"," 'unless': 866,\n"," 'face': 867,\n"," 'movie': 868,\n"," 'wife': 869,\n"," 'manager': 870,\n"," 'modern': 871,\n"," '\\xa0when': 872,\n"," 'eaten': 873,\n"," 'baked': 874,\n"," '11': 875,\n"," 'veggies': 876,\n"," 'spent': 877,\n"," 'level': 878,\n"," 'true': 879,\n"," 'total': 880,\n"," 'curry': 881,\n"," 'except': 882,\n"," 'noticed': 883,\n"," 'station': 884,\n"," 'salads': 885,\n"," 'taken': 886,\n"," 'mom': 887,\n"," 'easily': 888,\n"," 'wings': 889,\n"," 'talking': 890,\n"," 'bunch': 891,\n"," 'running': 892,\n"," 'perhaps': 893,\n"," 'thinking': 894,\n"," 'hope': 895,\n"," 'share': 896,\n"," 'reservation': 897,\n"," 'stuffed': 898,\n"," 'worked': 899,\n"," 'mostly': 900,\n"," 'turned': 901,\n"," 'fancy': 902,\n"," 'boyfriend': 903,\n"," 'american': 904,\n"," 'added': 905,\n"," 'strong': 906,\n"," 'understand': 907,\n"," \"\\xa0i've\": 908,\n"," 'heart': 909,\n"," 'south': 910,\n"," '00': 911,\n"," 'truly': 912,\n"," 'duck': 913,\n"," 'weeks': 914,\n"," 'bag': 915,\n"," 'immediately': 916,\n"," 'desserts': 917,\n"," 'means': 918,\n"," 'shoes': 919,\n"," 'spinach': 920,\n"," 'dressing': 921,\n"," 'dance': 922,\n"," 'playing': 923,\n"," 'credit': 924,\n"," 'burrito': 925,\n"," 'desk': 926,\n"," 'box': 927,\n"," 'literally': 928,\n"," 'girls': 929,\n"," 'authentic': 930,\n"," 'medium': 931,\n"," 'nights': 932,\n"," 'moved': 933,\n"," 'paying': 934,\n"," 'toast': 935,\n"," 'greasy': 936,\n"," 'foods': 937,\n"," 'saying': 938,\n"," 'chance': 939,\n"," 'salty': 940,\n"," 'apparently': 941,\n"," 'picked': 942,\n"," 'vegetarian': 943,\n"," 'mini': 944,\n"," 'sides': 945,\n"," 'longer': 946,\n"," 'mine': 947,\n"," 'ribs': 948,\n"," 'move': 949,\n"," 'filling': 950,\n"," 'anywhere': 951,\n"," 'products': 952,\n"," 'excited': 953,\n"," 'servers': 954,\n"," 'unfortunately': 955,\n"," 'hands': 956,\n"," 'chairs': 957,\n"," 'wines': 958,\n"," 'takes': 959,\n"," 's': 960,\n"," \"you've\": 961,\n"," 'window': 962,\n"," 'baby': 963,\n"," 'rich': 964,\n"," 'salt': 965,\n"," 'walls': 966,\n"," 'dogs': 967,\n"," 'says': 968,\n"," 'eye': 969,\n"," 'cozy': 970,\n"," 'strip': 971,\n"," 'toppings': 972,\n"," 'japanese': 973,\n"," 'fair': 974,\n"," 'tv': 975,\n"," 'massage': 976,\n"," 'touch': 977,\n"," 'alone': 978,\n"," 'creamy': 979,\n"," 'drinking': 980,\n"," 'm': 981,\n"," 'hell': 982,\n"," 'prefer': 983,\n"," 'single': 984,\n"," '\\xa0in': 985,\n"," 'meals': 986,\n"," 'despite': 987,\n"," 'vibe': 988,\n"," 'mac': 989,\n"," 'orange': 990,\n"," 'cocktails': 991,\n"," 'hang': 992,\n"," 'orders': 993,\n"," 'smaller': 994,\n"," 'lines': 995,\n"," 'overpriced': 996,\n"," 'seeing': 997,\n"," '\\xa0no': 998,\n"," 'st': 999,\n"," 'tons': 1000,\n"," ...}"]},"metadata":{"tags":[]},"execution_count":31}]},{"cell_type":"markdown","metadata":{"id":"VOzK2GoK2hsu","colab_type":"text"},"source":["We can then use the tokenizer to convert all texts in the training-set to lists of these tokens."]},{"cell_type":"markdown","metadata":{"id":"Ae6dc9fChWI1","colab_type":"text"},"source":[""]},{"cell_type":"code","metadata":{"id":"Z4dSCl0F2YmJ","colab_type":"code","colab":{}},"source":["X_train_tokens = tokenizer.texts_to_sequences(X_train)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"um_Tps-A2t2d","colab_type":"code","outputId":"99ec6c0b-4aaf-4e3a-85b4-1f6433f1b7c0","executionInfo":{"status":"ok","timestamp":1557180446114,"user_tz":420,"elapsed":421061,"user":{"displayName":"Neha Bindle","photoUrl":"https://lh5.googleusercontent.com/-AKdRkZAe6ns/AAAAAAAAAAI/AAAAAAAAAFk/gdyXnPRgma8/s64/photo.jpg","userId":"09892886772832107016"}},"colab":{"base_uri":"https://localhost:8080/","height":54}},"source":["\n","X_train[1]"],"execution_count":33,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'The only place inside the Loop that you can stay for $55/night. Also, the only place you can have a picnic dinner and get a little frisky on the 17th floor roof and then wake up in your room the next morning to an army of ants going in on your picnic leftovers.'"]},"metadata":{"tags":[]},"execution_count":33}]},{"cell_type":"code","metadata":{"id":"-GKziOCE2zwB","colab_type":"code","outputId":"60e981fe-c1a3-48af-bad2-275044e7dbe0","executionInfo":{"status":"ok","timestamp":1557180446115,"user_tz":420,"elapsed":420165,"user":{"displayName":"Neha Bindle","photoUrl":"https://lh5.googleusercontent.com/-AKdRkZAe6ns/AAAAAAAAAAI/AAAAAAAAAFk/gdyXnPRgma8/s64/photo.jpg","userId":"09892886772832107016"}},"colab":{"base_uri":"https://localhost:8080/","height":119}},"source":["np.array(X_train_tokens[1])"],"execution_count":34,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([  97,    5, 1478,   23,   18,  396, 1662,   65,    9,  119,   85,\n","          3, 2060, 3240,  118,    3,   49, 2060, 2204,  118,  396, 1662,\n","        118,   19,   20,  117, 2419,  976,  957, 7651,  215,   36,    1,\n","       4970,    8,   63,   67,  146,   15,  179,   11,   40,  190,  845,\n","         24,    8,    6,   16,  396, 3598,    4,   28, 1662,   11,  241,\n","        677,   42, 1182,   68,  631])"]},"metadata":{"tags":[]},"execution_count":34}]},{"cell_type":"markdown","metadata":{"id":"3rToCDDw3mUZ","colab_type":"text"},"source":[""]},{"cell_type":"markdown","metadata":{"id":"DhgXmCf73A4k","colab_type":"text"},"source":["We also need to convert the texts in the test-set to tokens."]},{"cell_type":"code","metadata":{"id":"Vh1cpnNf290L","colab_type":"code","colab":{}},"source":["X_test_tokens = tokenizer.texts_to_sequences(X_test)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"HbUNpQnC3Nvl","colab_type":"text"},"source":["Padding and Truncating Data¶\n","The Recurrent Neural Network can take sequences of arbitrary length as input, but in order to use a whole batch of data, the sequences need to have the same length. There are two ways of achieving this: (A) Either we ensure that all sequences in the entire data-set have the same length, or (B) we write a custom data-generator that ensures the sequences have the same length within each batch.\n","\n","Solution (A) is simpler but if we use the length of the longest sequence in the data-set, then we are wasting a lot of memory. This is particularly important for larger data-sets.\n","\n","So in order to make a compromise, we will use a sequence-length that covers most sequences in the data-set, and we will then truncate longer sequences and pad shorter sequences.\n","\n","First we count the number of tokens in all the sequences in the data-set."]},{"cell_type":"code","metadata":{"id":"VnonWXPc3VCC","colab_type":"code","colab":{}},"source":["num_tokens = [len(tokens) for tokens in X_train_tokens + X_test_tokens]\n","num_tokens = np.array(num_tokens)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"kE0eW9yh3nqT","colab_type":"text"},"source":["The average number of tokens in a sequence is:"]},{"cell_type":"code","metadata":{"id":"l_CvxbHQ33ZT","colab_type":"code","outputId":"11c07fcf-4bd8-4e28-a210-2a25f015a3e0","executionInfo":{"status":"ok","timestamp":1557180479416,"user_tz":420,"elapsed":450153,"user":{"displayName":"Neha Bindle","photoUrl":"https://lh5.googleusercontent.com/-AKdRkZAe6ns/AAAAAAAAAAI/AAAAAAAAAFk/gdyXnPRgma8/s64/photo.jpg","userId":"09892886772832107016"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["np.mean(num_tokens)"],"execution_count":37,"outputs":[{"output_type":"execute_result","data":{"text/plain":["136.61207649249124"]},"metadata":{"tags":[]},"execution_count":37}]},{"cell_type":"markdown","metadata":{"id":"rPRWwYok39Z-","colab_type":"text"},"source":["The maximum number of tokens in a sequence is:"]},{"cell_type":"code","metadata":{"id":"Mw1EM8DA3_-H","colab_type":"code","outputId":"d457cc84-1cbf-41f0-8d5b-35437d17121a","executionInfo":{"status":"ok","timestamp":1557180479418,"user_tz":420,"elapsed":448449,"user":{"displayName":"Neha Bindle","photoUrl":"https://lh5.googleusercontent.com/-AKdRkZAe6ns/AAAAAAAAAAI/AAAAAAAAAFk/gdyXnPRgma8/s64/photo.jpg","userId":"09892886772832107016"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["np.max(num_tokens)"],"execution_count":38,"outputs":[{"output_type":"execute_result","data":{"text/plain":["1327"]},"metadata":{"tags":[]},"execution_count":38}]},{"cell_type":"markdown","metadata":{"id":"-Fdl5ced4JZ8","colab_type":"text"},"source":["The max number of tokens we will allow is set to the average plus 2 standard deviations."]},{"cell_type":"code","metadata":{"id":"hww_AqTx4MEh","colab_type":"code","outputId":"e7d7d6cc-457d-40c6-cb23-5eca5f952f79","executionInfo":{"status":"ok","timestamp":1557180479549,"user_tz":420,"elapsed":447564,"user":{"displayName":"Neha Bindle","photoUrl":"https://lh5.googleusercontent.com/-AKdRkZAe6ns/AAAAAAAAAAI/AAAAAAAAAFk/gdyXnPRgma8/s64/photo.jpg","userId":"09892886772832107016"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["max_tokens = np.mean(num_tokens) + 2 * np.std(num_tokens)\n","max_tokens = int(max_tokens)\n","max_tokens"],"execution_count":39,"outputs":[{"output_type":"execute_result","data":{"text/plain":["355"]},"metadata":{"tags":[]},"execution_count":39}]},{"cell_type":"code","metadata":{"id":"5ta5aQ8f4Vc-","colab_type":"code","outputId":"0092bdc5-ebbe-44b4-f7ef-6673089be88e","executionInfo":{"status":"ok","timestamp":1557180479551,"user_tz":420,"elapsed":446184,"user":{"displayName":"Neha Bindle","photoUrl":"https://lh5.googleusercontent.com/-AKdRkZAe6ns/AAAAAAAAAAI/AAAAAAAAAFk/gdyXnPRgma8/s64/photo.jpg","userId":"09892886772832107016"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["np.sum(num_tokens < max_tokens) / len(num_tokens)"],"execution_count":40,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.9541236821345607"]},"metadata":{"tags":[]},"execution_count":40}]},{"cell_type":"markdown","metadata":{"id":"-gpSwjbO4biG","colab_type":"text"},"source":["When padding or truncating the sequences that have a different length, we need to determine if we want to do this padding or truncating 'pre' or 'post'. If a sequence is truncated, it means that a part of the sequence is simply thrown away. If a sequence is padded, it means that zeros are added to the sequence.\n","\n","So the choice of 'pre' or 'post' can be important because it determines whether we throw away the first or last part of a sequence when truncating, and it determines whether we add zeros to the beginning or end of the sequence when padding. This may confuse the Recurrent Neural Network."]},{"cell_type":"code","metadata":{"id":"f6Hsbc8W4hxw","colab_type":"code","colab":{}},"source":["pad = 'pre'\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"OCJdSfKF4kHQ","colab_type":"code","colab":{}},"source":["X_train_pad = pad_sequences(X_train_tokens, maxlen=max_tokens,\n","                            padding=pad, truncating=pad)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Ky_gNfeH5tus","colab_type":"code","colab":{}},"source":["X_test_pad = pad_sequences(X_test_tokens, maxlen=max_tokens,\n","                           padding=pad, truncating=pad)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"7woOO57951Kk","colab_type":"text"},"source":["We have now transformed the training-set into one big matrix of integers (tokens) with this shape:"]},{"cell_type":"code","metadata":{"id":"Nnxp4Gvd56L9","colab_type":"code","outputId":"ee9c96a5-ce5d-4e7f-d133-b2544e262cf9","executionInfo":{"status":"ok","timestamp":1557180489992,"user_tz":420,"elapsed":449368,"user":{"displayName":"Neha Bindle","photoUrl":"https://lh5.googleusercontent.com/-AKdRkZAe6ns/AAAAAAAAAAI/AAAAAAAAAFk/gdyXnPRgma8/s64/photo.jpg","userId":"09892886772832107016"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["\n","X_train_pad.shape"],"execution_count":44,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(481830, 355)"]},"metadata":{"tags":[]},"execution_count":44}]},{"cell_type":"markdown","metadata":{"id":"wH3_LUg-W-9G","colab_type":"text"},"source":[""]},{"cell_type":"markdown","metadata":{"id":"nH_lkVNEJtJT","colab_type":"text"},"source":[""]},{"cell_type":"markdown","metadata":{"id":"t73XrNAg6B29","colab_type":"text"},"source":["The matrix for the test-set has the same shape:"]},{"cell_type":"code","metadata":{"id":"QVS6Q1HW6DCv","colab_type":"code","outputId":"8649a08d-9446-4a24-e24d-780c54cfac0a","executionInfo":{"status":"ok","timestamp":1557180489993,"user_tz":420,"elapsed":448214,"user":{"displayName":"Neha Bindle","photoUrl":"https://lh5.googleusercontent.com/-AKdRkZAe6ns/AAAAAAAAAAI/AAAAAAAAAFk/gdyXnPRgma8/s64/photo.jpg","userId":"09892886772832107016"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["X_test_pad.shape"],"execution_count":45,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(206499, 355)"]},"metadata":{"tags":[]},"execution_count":45}]},{"cell_type":"markdown","metadata":{"id":"ff2kzZjx6L1Q","colab_type":"text"},"source":["Change of sequence of tokens into padded sequence.Note that when this is input to the Recurrent Neural Network, then it first inputs a lot of zeros. If we had padded 'post' then it would input the integer-tokens first and then a lot of zeros. This may confuse the Recurrent Neural Network.\n","\n"]},{"cell_type":"code","metadata":{"id":"1TuD19Tx6XM7","colab_type":"code","outputId":"a4a0a3ca-c61b-4565-929d-56f94191c1b3","executionInfo":{"status":"ok","timestamp":1557180489994,"user_tz":420,"elapsed":446895,"user":{"displayName":"Neha Bindle","photoUrl":"https://lh5.googleusercontent.com/-AKdRkZAe6ns/AAAAAAAAAAI/AAAAAAAAAFk/gdyXnPRgma8/s64/photo.jpg","userId":"09892886772832107016"}},"colab":{"base_uri":"https://localhost:8080/","height":578}},"source":["np.array(X_train_tokens[1])\n","X_train_pad[1]\n"],"execution_count":46,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","          0,    0,    0,    0,    0,    0,    0,    0,    0,   97,    5,\n","       1478,   23,   18,  396, 1662,   65,    9,  119,   85,    3, 2060,\n","       3240,  118,    3,   49, 2060, 2204,  118,  396, 1662,  118,   19,\n","         20,  117, 2419,  976,  957, 7651,  215,   36,    1, 4970,    8,\n","         63,   67,  146,   15,  179,   11,   40,  190,  845,   24,    8,\n","          6,   16,  396, 3598,    4,   28, 1662,   11,  241,  677,   42,\n","       1182,   68,  631], dtype=int32)"]},"metadata":{"tags":[]},"execution_count":46}]},{"cell_type":"markdown","metadata":{"id":"cjoL0cMU6hzx","colab_type":"text"},"source":["**Tokenizer Inverse Map**\n","\n","For some strange reason, the Keras implementation of a tokenizer does not seem to have the inverse mapping from integer-tokens back to words, which is needed to reconstruct text-strings from lists of tokens. So we make that mapping here."]},{"cell_type":"code","metadata":{"id":"pE2-gWMz6nap","colab_type":"code","colab":{}},"source":["idx = tokenizer.word_index\n","inverse_map = dict(zip(idx.values(), idx.keys()))"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"DTEF0gl17EID","colab_type":"text"},"source":["\n","Helper-function for converting a list of tokens back to a string of words."]},{"cell_type":"code","metadata":{"id":"249upoac7G93","colab_type":"code","colab":{}},"source":["def tokens_to_string(tokens):\n","    # Map from tokens back to words.\n","    words = [inverse_map[token] for token in tokens if token != 0]\n","    \n","    # Concatenate all words.\n","    text = \" \".join(words)\n","\n","    return text"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"KpGZa1Bo7JMT","colab_type":"code","outputId":"61c7bfa8-9d54-4120-a3a4-497a10364a52","executionInfo":{"status":"ok","timestamp":1557180490137,"user_tz":420,"elapsed":442123,"user":{"displayName":"Neha Bindle","photoUrl":"https://lh5.googleusercontent.com/-AKdRkZAe6ns/AAAAAAAAAAI/AAAAAAAAAFk/gdyXnPRgma8/s64/photo.jpg","userId":"09892886772832107016"}},"colab":{"base_uri":"https://localhost:8080/","height":54}},"source":["#For example, this is the original text from the data-set:\n","\n","X_train[1]\n"],"execution_count":49,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'The only place inside the Loop that you can stay for $55/night. Also, the only place you can have a picnic dinner and get a little frisky on the 17th floor roof and then wake up in your room the next morning to an army of ants going in on your picnic leftovers.'"]},"metadata":{"tags":[]},"execution_count":49}]},{"cell_type":"code","metadata":{"id":"CX83b1hj7UM8","colab_type":"code","outputId":"12fd3e0c-7d3f-4bed-9911-4753e87a215f","executionInfo":{"status":"ok","timestamp":1557180490139,"user_tz":420,"elapsed":440645,"user":{"displayName":"Neha Bindle","photoUrl":"https://lh5.googleusercontent.com/-AKdRkZAe6ns/AAAAAAAAAAI/AAAAAAAAAFk/gdyXnPRgma8/s64/photo.jpg","userId":"09892886772832107016"}},"colab":{"base_uri":"https://localhost:8080/","height":54}},"source":["tokens_to_string(X_train_tokens[1])"],"execution_count":50,"outputs":[{"output_type":"execute_result","data":{"text/plain":["\"love to chill at this car wash what is better than a lazy rainy day a very lazy sunny day car wash day they have two leather massage chairs that'll work out the kinks in your back while you wait for just 1 per so in of my car hmm i good wash for 10 12 \\xa0 complete also available\""]},"metadata":{"tags":[]},"execution_count":50}]},{"cell_type":"markdown","metadata":{"id":"Q1lwXbDO7nTq","colab_type":"text"},"source":["**Create the Recurrent Neural Network**\n"]},{"cell_type":"code","metadata":{"id":"aUlcYzSR7war","colab_type":"code","colab":{}},"source":["model = Sequential()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"jOUcjmQA70D0","colab_type":"code","colab":{}},"source":["embedding_size = 8\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"zEiHGsop7243","colab_type":"code","colab":{}},"source":["model.add(Embedding(input_dim=num_words,\n","                    output_dim=embedding_size,\n","                    input_length=max_tokens,\n","                    name='layer_embedding'))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"RSxS0bQ4762I","colab_type":"code","colab":{}},"source":["#Adding the gated GRU\n","model.add(GRU(units=16, return_sequences=True))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"3HEo-f3j8DP6","colab_type":"code","colab":{}},"source":["#Adding the second GRU with 8 output units\n","model.add(GRU(units=8, return_sequences=True))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"BuYNAtaR8Lel","colab_type":"code","colab":{}},"source":["# This code adds the third and final GRU with 4 output units. This will be followed by a dense-layer, so it should only give the final output of the GRU and not a whole sequence of outputs.\n","\n","model.add(GRU(units=4))"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"43DIqzSy8YrQ","colab_type":"text"},"source":["dd a fully-connected / dense layer which computes a value between 0.0 and 1.0 that will be used as the classification output."]},{"cell_type":"code","metadata":{"id":"Iuy0Ns1Z8elX","colab_type":"code","colab":{}},"source":["model.add(Dense(1, activation='sigmoid'))\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"5tMNpwiZ8jQ2","colab_type":"code","colab":{}},"source":["#Adam optimizer with the given learning-rate.\n","optimizer = Adam(lr=1e-3)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Xd22QhtM8pir","colab_type":"code","colab":{}},"source":["#Compile the Keras model so it is ready for training.\n","model.compile(loss='binary_crossentropy',\n","              optimizer=optimizer,\n","              metrics=['accuracy'])\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"UKp48z8I8t-O","colab_type":"code","outputId":"d035f2b1-0395-4d69-836d-0b1bd1077e61","executionInfo":{"status":"ok","timestamp":1557180552183,"user_tz":420,"elapsed":238,"user":{"displayName":"Neha Bindle","photoUrl":"https://lh5.googleusercontent.com/-AKdRkZAe6ns/AAAAAAAAAAI/AAAAAAAAAFk/gdyXnPRgma8/s64/photo.jpg","userId":"09892886772832107016"}},"colab":{"base_uri":"https://localhost:8080/","height":340}},"source":["\n","model.summary()"],"execution_count":79,"outputs":[{"output_type":"stream","text":["_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","layer_embedding (Embedding)  (None, 355, 8)            80000     \n","_________________________________________________________________\n","gru_3 (GRU)                  (None, 355, 8)            408       \n","_________________________________________________________________\n","gru_4 (GRU)                  (None, 355, 16)           1200      \n","_________________________________________________________________\n","gru_5 (GRU)                  (None, 355, 8)            600       \n","_________________________________________________________________\n","gru_6 (GRU)                  (None, 4)                 156       \n","_________________________________________________________________\n","dense_1 (Dense)              (None, 1)                 5         \n","=================================================================\n","Total params: 82,369\n","Trainable params: 82,369\n","Non-trainable params: 0\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"aPleqvXQ8zJT","colab_type":"text"},"source":["**Train the Recurrent Neural Network**\n","\n","We can now train the model. Note that we are using the data-set with the padded sequences. We use 5% of the training-set as a small validation-set, so we have a rough idea whether the model is generalizing well or if it is perhaps over-fitting to the training-set."]},{"cell_type":"code","metadata":{"id":"kjcKGk7lZ-tZ","colab_type":"code","colab":{}},"source":["#print(y_train.loc[y_train['Class'] == \"N\"])\n","\n","def mapToBinary(x):\n","  if x == 'Y':\n","    return 1\n","  else:\n","    return 0\n","  \n","y_train_bin = list(map(mapToBinary, y_train))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"iEzDIMOP5Bxk","colab_type":"code","colab":{}},"source":["y_test_bin = list(map(mapToBinary, y_test))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"fFb4wNuXjEoK","colab_type":"code","outputId":"b69f8be9-f5eb-47b7-cabe-c66796917c70","executionInfo":{"status":"error","timestamp":1557180559239,"user_tz":420,"elapsed":239,"user":{"displayName":"Neha Bindle","photoUrl":"https://lh5.googleusercontent.com/-AKdRkZAe6ns/AAAAAAAAAAI/AAAAAAAAAFk/gdyXnPRgma8/s64/photo.jpg","userId":"09892886772832107016"}},"colab":{"base_uri":"https://localhost:8080/","height":232}},"source":[""],"execution_count":82,"outputs":[{"output_type":"error","ename":"AttributeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m<ipython-input-82-985b3920bc92>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0macc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mval_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mAttributeError\u001b[0m: 'Sequential' object has no attribute 'history'"]}]},{"cell_type":"code","metadata":{"id":"KvcbfmwK87I_","colab_type":"code","outputId":"bcc9de9c-3f30-4a91-9b74-c9c136f11bab","executionInfo":{"status":"ok","timestamp":1557200187435,"user_tz":420,"elapsed":13655691,"user":{"displayName":"Neha Bindle","photoUrl":"https://lh5.googleusercontent.com/-AKdRkZAe6ns/AAAAAAAAAAI/AAAAAAAAAFk/gdyXnPRgma8/s64/photo.jpg","userId":"09892886772832107016"}},"colab":{"base_uri":"https://localhost:8080/","height":326}},"source":["%%time\n","model.fit(X_train_pad, y_train, \n","          validation_split=0.2, epochs=5, batch_size=64)"],"execution_count":83,"outputs":[{"output_type":"stream","text":["Train on 385464 samples, validate on 96366 samples\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.cast instead.\n","Epoch 1/5\n","385464/385464 [==============================] - 3928s 10ms/sample - loss: 0.6006 - acc: 0.6667 - val_loss: 0.5805 - val_acc: 0.6883\n","Epoch 2/5\n","385464/385464 [==============================] - 3947s 10ms/sample - loss: 0.5688 - acc: 0.6965 - val_loss: 0.5763 - val_acc: 0.6909\n","Epoch 3/5\n","385464/385464 [==============================] - 3927s 10ms/sample - loss: 0.5592 - acc: 0.7049 - val_loss: 0.5718 - val_acc: 0.6946\n","Epoch 4/5\n","385464/385464 [==============================] - 3914s 10ms/sample - loss: 0.5555 - acc: 0.7066 - val_loss: 0.5765 - val_acc: 0.6939\n","Epoch 5/5\n","385464/385464 [==============================] - 3889s 10ms/sample - loss: 0.5470 - acc: 0.7149 - val_loss: 0.5767 - val_acc: 0.6914\n","CPU times: user 9h 29min 1s, sys: 45min 28s, total: 10h 14min 29s\n","Wall time: 5h 26min 50s\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<tensorflow.python.keras.callbacks.History at 0x7fc6cc293c50>"]},"metadata":{"tags":[]},"execution_count":83}]},{"cell_type":"code","metadata":{"id":"JZX12Kf0Hl5-","colab_type":"code","colab":{}},"source":["model.save('gdata/my_modelrnn.h5')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"8L1cMPYWCeBp","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":232},"outputId":"1949f478-43c4-4d61-8c96-a9ca545f273f","executionInfo":{"status":"error","timestamp":1557200228417,"user_tz":420,"elapsed":189,"user":{"displayName":"Neha Bindle","photoUrl":"https://lh5.googleusercontent.com/-AKdRkZAe6ns/AAAAAAAAAAI/AAAAAAAAAFk/gdyXnPRgma8/s64/photo.jpg","userId":"09892886772832107016"}}},"source":["history = model.history\n","\n","\n","acc = history.history['accuracy']\n","val_acc = history.history['val_accuracy']\n","loss = history.history['loss']\n","val_loss = history.history['val_loss']\n","\n","epochs = range(len(acc))\n","\n","plt.plot(epochs, acc, 'bo', label='Training acc')\n","plt.plot(epochs, val_acc, 'b', label='Validation acc')\n","plt.title('Training and validation accuracy using ')\n","plt.legend()\n","\n","plt.figure()\n","\n","plt.plot(epochs, loss, 'bo', label='Training loss')\n","plt.plot(epochs, val_loss, 'b', label='Validation loss')\n","plt.title('Training and validation loss')\n","plt.legend()\n","\n","plt.show()"],"execution_count":87,"outputs":[{"output_type":"error","ename":"KeyError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)","\u001b[0;32m<ipython-input-87-985b3920bc92>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0macc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mval_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyError\u001b[0m: 'accuracy'"]}]},{"cell_type":"code","metadata":{"id":"O46QrFzJN6sx","colab_type":"code","colab":{}},"source":["\n","model.save('gdata/my_modelnew.h5')  "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"N1QAHnkh5DqT","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":136},"outputId":"27c2546e-e0e8-49db-862b-80c784898df3","executionInfo":{"status":"ok","timestamp":1557200241879,"user_tz":420,"elapsed":213,"user":{"displayName":"Neha Bindle","photoUrl":"https://lh5.googleusercontent.com/-AKdRkZAe6ns/AAAAAAAAAAI/AAAAAAAAAFk/gdyXnPRgma8/s64/photo.jpg","userId":"09892886772832107016"}}},"source":["X_test_pad"],"execution_count":89,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[   0,    0,    0, ..., 5369,  998,   52],\n","       [   0,    0,    0, ...,    4,  895,   24],\n","       [   0,    0,    0, ...,  139,   61, 1408],\n","       ...,\n","       [   0,    0,    0, ...,  245,    6,   29],\n","       [   0,    0,    0, ...,  310,    8,    1],\n","       [   0,    0,    0, ..., 7858, 1470,  378]], dtype=int32)"]},"metadata":{"tags":[]},"execution_count":89}]},{"cell_type":"code","metadata":{"id":"xYLE7XGWN5CK","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"1JqTZnJ_34XV","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":68},"outputId":"ed3a2740-f5e8-4b3d-e7cd-0c64379adf4f","executionInfo":{"status":"ok","timestamp":1557200922601,"user_tz":420,"elapsed":676935,"user":{"displayName":"Neha Bindle","photoUrl":"https://lh5.googleusercontent.com/-AKdRkZAe6ns/AAAAAAAAAAI/AAAAAAAAAFk/gdyXnPRgma8/s64/photo.jpg","userId":"09892886772832107016"}}},"source":["# Performance on Test-Set\n","# Now that the model has been trained we can calculate its classification accuracy on the test-set.\n","\n","%%time\n","result = model.evaluate(X_test_pad, y_test_bin)"],"execution_count":90,"outputs":[{"output_type":"stream","text":["206499/206499 [==============================] - 677s 3ms/sample - loss: 0.5887 - acc: 0.6309\n","CPU times: user 19min 10s, sys: 1min 22s, total: 20min 33s\n","Wall time: 11min 16s\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"7UysFS0gaFKi","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":68},"outputId":"7e78831f-31ef-4130-ece0-67f60ceac1c4","executionInfo":{"status":"ok","timestamp":1557201620839,"user_tz":420,"elapsed":331881,"user":{"displayName":"Neha Bindle","photoUrl":"https://lh5.googleusercontent.com/-AKdRkZAe6ns/AAAAAAAAAAI/AAAAAAAAAFk/gdyXnPRgma8/s64/photo.jpg","userId":"09892886772832107016"}}},"source":["%%time\n","result = model.evaluate(X_test_pad, y_test)"],"execution_count":91,"outputs":[{"output_type":"stream","text":["206499/206499 [==============================] - 691s 3ms/sample - loss: 0.5773 - acc: 0.6906\n","CPU times: user 19min 24s, sys: 1min 22s, total: 20min 47s\n","Wall time: 11min 30s\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"YiGfmD2z6dvj","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"ea1b3172-c693-448f-ef13-325c7a3ba6b1","executionInfo":{"status":"ok","timestamp":1557201620975,"user_tz":420,"elapsed":142,"user":{"displayName":"Neha Bindle","photoUrl":"https://lh5.googleusercontent.com/-AKdRkZAe6ns/AAAAAAAAAAI/AAAAAAAAAFk/gdyXnPRgma8/s64/photo.jpg","userId":"09892886772832107016"}}},"source":["print(\"Accuracy: {0:.2%}\".format(result[1]))"],"execution_count":92,"outputs":[{"output_type":"stream","text":["Accuracy: 69.06%\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"2cUYR-bmdkS7","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":358},"outputId":"910e96cc-ff0a-4315-a26d-71df18042efe","executionInfo":{"status":"error","timestamp":1557202251054,"user_tz":420,"elapsed":626554,"user":{"displayName":"Neha Bindle","photoUrl":"https://lh5.googleusercontent.com/-AKdRkZAe6ns/AAAAAAAAAAI/AAAAAAAAAFk/gdyXnPRgma8/s64/photo.jpg","userId":"09892886772832107016"}}},"source":["predictions = model.predict(X_test_pad)\n","predictions_bin = list(map(lambda x: 1 if x>=0.5 else 0, predictions))\n","predictions_bin\n","\n","from sklearn import metrics\n","\n","print(metrics.classification_report(y_test,predictions))\n"],"execution_count":93,"outputs":[{"output_type":"error","ename":"ValueError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-93-ea7d6f923a15>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclassification_report\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;31m# print(metrics.classification_report(y_test_bin,predictions_bin))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py\u001b[0m in \u001b[0;36mclassification_report\u001b[0;34m(y_true, y_pred, labels, target_names, sample_weight, digits, output_dict)\u001b[0m\n\u001b[1;32m   1522\u001b[0m     \"\"\"\n\u001b[1;32m   1523\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1524\u001b[0;31m     \u001b[0my_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1525\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m     \u001b[0mlabels_given\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     79\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_type\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m         raise ValueError(\"Classification metrics can't handle a mix of {0} \"\n\u001b[0;32m---> 81\u001b[0;31m                          \"and {1} targets\".format(type_true, type_pred))\n\u001b[0m\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m     \u001b[0;31m# We can't have more than one value on y_type => The set is no more needed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: Classification metrics can't handle a mix of binary and continuous targets"]}]},{"cell_type":"code","metadata":{"id":"Q2U30XvRaD-N","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"SaVG1xjm8DlW","colab_type":"code","colab":{}},"source":["model.save('gdata/my_modelrnn.h5')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"F95lxb8WDk7W","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"qAPiaxwF5JIK","colab_type":"code","colab":{}},"source":["\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"WxocJLf95H-h","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"pML5erMwRN6x","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"fzVw7AkDcvdi","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"nUBS2JTGRdx6","colab_type":"code","colab":{}},"source":["\n","\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Xx4Xd0gJc79E","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"vOnVcCuHdEi-","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"2d74LLuKcbTC","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"bqiwr4Nteumo","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"BlnXL3ufez9s","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}